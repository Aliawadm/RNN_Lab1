{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbfec32-1b50-43e9-a648-c9879dc4b79c",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1eb792b-8cfc-44d8-9d1c-0bf8c403fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7705c2-42a1-4047-bbac-3a0f7465e032",
   "metadata": {},
   "source": [
    "# Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31467209-c5d3-4a4f-a79f-4a2f6e68ce85",
   "metadata": {},
   "source": [
    "### Load Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef01310-47d6-44ac-aff1-abf4da07a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets, train_labels = [], []\n",
    "\n",
    "pos = os.getcwd() + '/corpus/arabic_tweets/pos/'  # Replace with the actual directory path\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(pos):\n",
    "    if filename.endswith('.txt'):  # Select only text files\n",
    "        file_path = os.path.join(pos, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "            file_content = file.read()\n",
    "            train_tweets.append(file_content)\n",
    "            train_labels.append(\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d463c-377c-4730-9398-cb5fcaa5e44b",
   "metadata": {},
   "source": [
    "### Load Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937bb606-b07a-4e7e-a83a-1ccce2b18263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the txt file negative tweet\n",
    "pos = os.getcwd() + '/corpus/arabic_tweets/neg/'  # Replace with the actual directory path\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(pos):\n",
    "    if filename.endswith('.txt'):  # Select only text files\n",
    "        file_path = os.path.join(pos, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "            file_content = file.read()\n",
    "            train_tweets.append(file_content)\n",
    "            train_labels.append(\"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e8e33-f28b-4402-ab6d-f4925c1db165",
   "metadata": {},
   "source": [
    "### Build a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743b5741-d234-4d22-a833-76ec742cd6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>نحن الذين يتحول كل ما نود أن نقوله إلى دعاء لل...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>وفي النهاية لن يبقىٰ معك آحدإلا من رأىٰ الجمال...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>نمش ننوم ما دا ديل ولادنا 💚\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>تعدل النت وشفتها ✌\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🎥 المهمة الأولى في \"جدة\" ✔💪🏼 💙 #الهلال #فيديو_...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets    Labels\n",
       "0  نحن الذين يتحول كل ما نود أن نقوله إلى دعاء لل...  positive\n",
       "1  وفي النهاية لن يبقىٰ معك آحدإلا من رأىٰ الجمال...  positive\n",
       "2                      نمش ننوم ما دا ديل ولادنا 💚\\n  positive\n",
       "3                               تعدل النت وشفتها ✌\\n  positive\n",
       "4  🎥 المهمة الأولى في \"جدة\" ✔💪🏼 💙 #الهلال #فيديو_...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dic = {\n",
    "    'Tweets' : train_tweets,\n",
    "    'Labels' : train_labels\n",
    "}\n",
    "\n",
    "train_corpus = pd.DataFrame(train_dic)\n",
    "train_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b046ada-13fc-45d2-9056-b4115de8e812",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "##### Explore your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6d563b-a771-43b4-8e43-3688275b1f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58164, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58159</th>\n",
       "      <td>#أمي فقيدتي وأن مرت الأيام.. وبدأ الجميع بنسيا...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58160</th>\n",
       "      <td>مره في السنه ما كل اسبوع عاد 😢\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58161</th>\n",
       "      <td>#يوم_الجمعه اسال الله عز وجل في هذا اليوم الفض...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58162</th>\n",
       "      <td>يعني الغاء العقود الاولي كانت تسكيته لنا شسالف...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58163</th>\n",
       "      <td>الفار 🐀 في عهد خليل جلال 😲\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets    Labels\n",
       "58159  #أمي فقيدتي وأن مرت الأيام.. وبدأ الجميع بنسيا...  negative\n",
       "58160                   مره في السنه ما كل اسبوع عاد 😢\\n  negative\n",
       "58161  #يوم_الجمعه اسال الله عز وجل في هذا اليوم الفض...  negative\n",
       "58162  يعني الغاء العقود الاولي كانت تسكيته لنا شسالف...  negative\n",
       "58163                       الفار 🐀 في عهد خليل جلال 😲\\n  negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tweets</th>\n",
       "      <td>58164</td>\n",
       "      <td>36419</td>\n",
       "      <td>بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>58164</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>29262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count unique                                                top   freq\n",
       "Tweets  58164  36419  بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...    473\n",
       "Labels  58164      2                                           positive  29262"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus.describe().round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58164 entries, 0 to 58163\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tweets  58164 non-null  object\n",
      " 1   Labels  58164 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 908.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweets    0\n",
       "Labels    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels\n",
       "positive    29262\n",
       "negative    28902\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[\"Labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8d4a6-89a4-47b1-bf43-08dc09b97506",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8d9fa-6fb7-4352-aadb-3abeb932c412",
   "metadata": {},
   "source": [
    "### Shuffle all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "246bb815-274b-43a3-9d60-967a5864a6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>افا ليش 💔\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#يسقط_حكم_تميم نصر_اللات المكنى بزميره_ابليس ي...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>گم #ﻫﻲ ﺻﻌبة لحظﺎﺕ #ﺍﻹﺷتيﺎﻕ ﻟﻤﻦ😔 ﻻ ﻳﻤگن ﺭوﻳﺘﻬﻢ ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اوه مااي قادد 😱😱 نهاية ترايجيدية بكل معنى الكل...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سيم سيم 😢\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58159</th>\n",
       "      <td>سحب على مبلغ مالي 💰 لمتابعي #كشكول 👍🏻 المطلوب:...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58160</th>\n",
       "      <td>“علامة حب الله 🌱 قال ابن أبي الحواري : علامة ح...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58161</th>\n",
       "      <td>🛑همتكم مساعدتها في تعقيم واخصاء العدد٢ عشان تر...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58162</th>\n",
       "      <td>سمراء تكحلت فأربكت قلب ذاك الذي تاب عن العشق 💚\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58163</th>\n",
       "      <td>عربة السوشي تحل مكان عربة الكشري 🤔\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets    Labels\n",
       "0                                            افا ليش 💔\\n  negative\n",
       "1      #يسقط_حكم_تميم نصر_اللات المكنى بزميره_ابليس ي...  positive\n",
       "2      گم #ﻫﻲ ﺻﻌبة لحظﺎﺕ #ﺍﻹﺷتيﺎﻕ ﻟﻤﻦ😔 ﻻ ﻳﻤگن ﺭوﻳﺘﻬﻢ ...  negative\n",
       "3      اوه مااي قادد 😱😱 نهاية ترايجيدية بكل معنى الكل...  negative\n",
       "4                                            سيم سيم 😢\\n  negative\n",
       "...                                                  ...       ...\n",
       "58159  سحب على مبلغ مالي 💰 لمتابعي #كشكول 👍🏻 المطلوب:...  positive\n",
       "58160  “علامة حب الله 🌱 قال ابن أبي الحواري : علامة ح...  positive\n",
       "58161  🛑همتكم مساعدتها في تعقيم واخصاء العدد٢ عشان تر...  negative\n",
       "58162   سمراء تكحلت فأربكت قلب ذاك الذي تاب عن العشق 💚\\n  positive\n",
       "58163               عربة السوشي تحل مكان عربة الكشري 🤔\\n  negative\n",
       "\n",
       "[58164 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_corpus.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10a499-afa6-4d35-aa8a-53dbcae8e557",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "**Hint: remove URLs, Hashtags, alphanumeric characters, punctuation marks, stop words, extra spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d141959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_pattern = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "hashtag_pattern = r\"#\\w+\"\n",
    "mention_pattern = r\"@\\w+\"\n",
    "alphanumeric_pattern = r\"\\w*\\d\\w*\"\n",
    "punctuation_pattern = r\"[^\\w\\s]\"\n",
    "retweet_pattern = r\"^RT[\\s]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "957b0161-4c2d-4f33-90a3-e8892a27455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "    return frozenset(stop_set)\n",
    "\n",
    "def process_text(text, stop_words):\n",
    "    # Remove URLs\n",
    "    text = re.sub(URL_pattern, '', text)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text = re.sub(hashtag_pattern, '', text)\n",
    "    \n",
    "    # Remove mention\n",
    "    text = re.sub(mention_pattern, '', text)\n",
    "\n",
    "    # Remove alphanumeric characters\n",
    "    text = re.sub(alphanumeric_pattern, '', text)\n",
    "\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(punctuation_pattern, '', text)\n",
    "    \n",
    "    # Remove Retweet marks\n",
    "    text = re.sub(retweet_pattern, '', text)\n",
    "\n",
    "    # Remove stop words using the provided set\n",
    "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5996172",
   "metadata": {},
   "source": [
    "#### Now Clean your text using above function or implement it from scrach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e2c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=load_stopwords(R\"C:\\Users\\HP\\Desktop\\jup\\RNN_Lab1\\corpus\\Stop_Words.txt\")\n",
    "c=0\n",
    "for i in df[\"Tweets\"]:\n",
    "  df.loc[c,\"Tweets\"]=process_text(i,stopwords)\n",
    "  c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>افا ليش</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>نصر_اللات المكنى بزميره_ابليس يقول خميني عربي ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>گم ﺻﻌبة لحظﺎﺕ ﻟﻤﻦ ﻻ ﻳﻤگن ﺭوﻳﺘﻬﻢ ﺣﺘﻰ</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اوه مااي قادد ترايجيدية بكل معنى الكلمة ابددعو...</td>\n",
       "      <td>negative</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سيم سيم</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58159</th>\n",
       "      <td>سحب مبلغ مالي لمتابعي المطلوب شي بس رتويت السح...</td>\n",
       "      <td>positive</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58160</th>\n",
       "      <td>علامة حب الله ابن أبي الحواري علامة حب الله حب...</td>\n",
       "      <td>positive</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58161</th>\n",
       "      <td>همتكم مساعدتها تعقيم واخصاء عشان تروح تبني وتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58162</th>\n",
       "      <td>سمراء تكحلت فأربكت قلب ذاك تاب العشق</td>\n",
       "      <td>positive</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58163</th>\n",
       "      <td>عربة السوشي تحل مكان عربة الكشري</td>\n",
       "      <td>negative</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets    Labels  length\n",
       "0                                                افا ليش  negative       2\n",
       "1      نصر_اللات المكنى بزميره_ابليس يقول خميني عربي ...  positive      17\n",
       "2                    گم ﺻﻌبة لحظﺎﺕ ﻟﻤﻦ ﻻ ﻳﻤگن ﺭوﻳﺘﻬﻢ ﺣﺘﻰ  negative       8\n",
       "3      اوه مااي قادد ترايجيدية بكل معنى الكلمة ابددعو...  negative      16\n",
       "4                                                سيم سيم  negative       2\n",
       "...                                                  ...       ...     ...\n",
       "58159  سحب مبلغ مالي لمتابعي المطلوب شي بس رتويت السح...  positive      12\n",
       "58160  علامة حب الله ابن أبي الحواري علامة حب الله حب...  positive      20\n",
       "58161  همتكم مساعدتها تعقيم واخصاء عشان تروح تبني وتت...  negative      11\n",
       "58162               سمراء تكحلت فأربكت قلب ذاك تاب العشق  positive       7\n",
       "58163                   عربة السوشي تحل مكان عربة الكشري  negative       6\n",
       "\n",
       "[58164 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0cb63",
   "metadata": {},
   "source": [
    "#### Extra: you could do stemming or lemmatization before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160549cf-bffd-4205-a8fa-a6aa0695bcd8",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>افا ليش</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>نصر_اللات المكنى بزميره_ابليس يقول خميني عربي ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>گم ﺻﻌبة لحظﺎﺕ ﻟﻤﻦ ﻻ ﻳﻤگن ﺭوﻳﺘﻬﻢ ﺣﺘﻰ</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اوه مااي قادد ترايجيدية بكل معنى الكلمة ابددعو...</td>\n",
       "      <td>negative</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سيم سيم</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58159</th>\n",
       "      <td>سحب مبلغ مالي لمتابعي المطلوب شي بس رتويت السح...</td>\n",
       "      <td>positive</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58160</th>\n",
       "      <td>علامة حب الله ابن أبي الحواري علامة حب الله حب...</td>\n",
       "      <td>positive</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58161</th>\n",
       "      <td>همتكم مساعدتها تعقيم واخصاء عشان تروح تبني وتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58162</th>\n",
       "      <td>سمراء تكحلت فأربكت قلب ذاك تاب العشق</td>\n",
       "      <td>positive</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58163</th>\n",
       "      <td>عربة السوشي تحل مكان عربة الكشري</td>\n",
       "      <td>negative</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets    Labels  length\n",
       "0                                                افا ليش  negative       2\n",
       "1      نصر_اللات المكنى بزميره_ابليس يقول خميني عربي ...  positive      17\n",
       "2                    گم ﺻﻌبة لحظﺎﺕ ﻟﻤﻦ ﻻ ﻳﻤگن ﺭوﻳﺘﻬﻢ ﺣﺘﻰ  negative       8\n",
       "3      اوه مااي قادد ترايجيدية بكل معنى الكلمة ابددعو...  negative      16\n",
       "4                                                سيم سيم  negative       2\n",
       "...                                                  ...       ...     ...\n",
       "58159  سحب مبلغ مالي لمتابعي المطلوب شي بس رتويت السح...  positive      12\n",
       "58160  علامة حب الله ابن أبي الحواري علامة حب الله حب...  positive      20\n",
       "58161  همتكم مساعدتها تعقيم واخصاء عشان تروح تبني وتت...  negative      11\n",
       "58162               سمراء تكحلت فأربكت قلب ذاك تاب العشق  positive       7\n",
       "58163                   عربة السوشي تحل مكان عربة الكشري  negative       6\n",
       "\n",
       "[58164 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"length\"]=df[\"Tweets\"].apply(lambda x:len(x.split(\" \")))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=df[\"length\"].mean().astype(int)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f152bfd-478f-4cdd-b17e-885d4649019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df[\"Tweets\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58164"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  72840\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(corpus) \n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "num_classes = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Total number of words: \", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba90d2-7712-4e80-9120-c82f495b5f66",
   "metadata": {},
   "source": [
    "# Text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "labels = []\n",
    "for sequence in sequences:\n",
    "    for i in range(1, len(sequence)):\n",
    "        n_gram_sequence = sequence[:i+1]\n",
    "        input_sequences.append(n_gram_sequence[:-1])\n",
    "        labels.append(n_gram_sequence[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c31c7d-0375-4ef2-9f51-dccef70793d3",
   "metadata": {},
   "source": [
    "# Pad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = pad_sequences(input_sequences, maxlen=mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d0909-8e90-4aef-9ddb-42c3597791cb",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8 # 80% for the train\n",
    "split_index = int(split_ratio * len(input_sequences))\n",
    "x_train, y_train = input_sequences[:split_index], labels[:split_index]\n",
    "x_test, y_test = input_sequences[split_index:], labels[split_index:] # 20 for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, tokenizer, sequences, labels, batch_size, max_sequence_length, num_classes):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = np.random.choice(len(self.sequences), size=self.batch_size, replace=False)\n",
    "        batch_sequences = [self.sequences[i] for i in batch_indices]\n",
    "        batch_labels = [self.labels[i] for i in batch_indices]\n",
    "        x = pad_sequences(batch_sequences, maxlen=self.max_sequence_length)\n",
    "        y = self.one_hot_encode(batch_labels)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def one_hot_encode(self, labels):\n",
    "        encoded_labels = np.zeros((len(labels), self.num_classes), dtype=np.float32)\n",
    "        for i, label in enumerate(labels):\n",
    "            encoded_labels[i, label] = 1.0\n",
    "        return encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = DataGenerator(tokenizer, x_train, y_train, 32, mean, num_classes)\n",
    "test_data_generator = DataGenerator(tokenizer, x_test, y_test, 32, mean, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47efb8b2-7635-48ba-a4ae-4118862e74a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10648/10648 [==============================] - 3647s 342ms/step - loss: 8.0054 - accuracy: 0.1718\n",
      "Epoch 2/10\n",
      "10648/10648 [==============================] - 3302s 310ms/step - loss: 5.7777 - accuracy: 0.3798\n",
      "Epoch 3/10\n",
      "10648/10648 [==============================] - 3240s 304ms/step - loss: 4.8879 - accuracy: 0.4621\n",
      "Epoch 4/10\n",
      "10648/10648 [==============================] - 3245s 305ms/step - loss: 4.3489 - accuracy: 0.5093\n",
      "Epoch 5/10\n",
      "10648/10648 [==============================] - 3249s 305ms/step - loss: 3.9550 - accuracy: 0.5440\n",
      "Epoch 6/10\n",
      "10648/10648 [==============================] - 3281s 308ms/step - loss: 3.6433 - accuracy: 0.5728\n",
      "Epoch 7/10\n",
      "10648/10648 [==============================] - 3265s 307ms/step - loss: 3.4234 - accuracy: 0.5926\n",
      "Epoch 8/10\n",
      "10648/10648 [==============================] - 3288s 309ms/step - loss: 3.2368 - accuracy: 0.6092\n",
      "Epoch 9/10\n",
      "10648/10648 [==============================] - 3285s 308ms/step - loss: 3.0708 - accuracy: 0.6261\n",
      "Epoch 10/10\n",
      "10648/10648 [==============================] - 3472s 326ms/step - loss: 2.9515 - accuracy: 0.6377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cf653e97f0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_classes, output_dim=100, input_length=mean))\n",
    "model.add(SimpleRNN(100, return_sequences=True))\n",
    "model.add(SimpleRNN(100))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_data_generator, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the time to run the RNN on the train set is 554 minutes ≈  9.233 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a35492-747b-4fea-a80c-1602ff36da21",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dea5fb34-e15c-45cf-bf39-5a4c65a28705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10648/10648 [==============================] - 4155s 390ms/step - loss: 8.2105 - accuracy: 0.1363\n",
      "Epoch 2/3\n",
      "10648/10648 [==============================] - 3995s 375ms/step - loss: 6.0715 - accuracy: 0.3322\n",
      "Epoch 3/3\n",
      "10648/10648 [==============================] - 4727s 444ms/step - loss: 4.9849 - accuracy: 0.4374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cf671d52e0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(Embedding(input_dim=num_classes, output_dim=100, input_length=mean))\n",
    "model_LSTM.add(LSTM(units=128))\n",
    "model_LSTM.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model_LSTM.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_LSTM.fit(train_data_generator, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  the time to run the LSTM on the train set is 214 minutes ≈ 3.5667 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e105a33-8de7-406f-a5fb-c1a558c7bb9d",
   "metadata": {},
   "source": [
    "# Evaulation and Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a956b35-0604-44d5-87f2-eacfb36870d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 9, 100)            7284000   \n",
      "                                                                 \n",
      " simple_rnn_10 (SimpleRNN)   (None, 9, 100)            20100     \n",
      "                                                                 \n",
      " simple_rnn_11 (SimpleRNN)   (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 72840)             7356840   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14681040 (56.00 MB)\n",
      "Trainable params: 14681040 (56.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 9, 100)            7284000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               117248    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 72840)             9396360   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16797608 (64.08 MB)\n",
      "Trainable params: 16797608 (64.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10208\\3778774563.py:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  keras.models.save_model(model, \"model.h5\")\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10208\\3778774563.py:3: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  keras.models.save_model(model_LSTM, \"model_LSTM.h5\")\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.models.save_model(model, \"model.h5\")\n",
    "keras.models.save_model(model_LSTM, \"model_LSTM.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662/2662 [==============================] - 254s 95ms/step - loss: 6.5365 - accuracy: 0.4505\n",
      "Evaulation for RNN model:\n",
      "6.536467552185059\n",
      "0.4504719078540802\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data_generator)\n",
    "print(\"Evaulation for RNN model:\")\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662/2662 [==============================] - 334s 125ms/step - loss: 6.8272 - accuracy: 0.3849\n",
      "Evaulation for LSTM model:\n",
      "6.827205657958984\n",
      "0.3848962187767029\n"
     ]
    }
   ],
   "source": [
    "loss_LSTM, accuracy_LSTM = model_LSTM.evaluate(test_data_generator)\n",
    "print(\"Evaulation for LSTM model:\")\n",
    "print(loss_LSTM)\n",
    "print(accuracy_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(seed_text, num_of_words):\n",
    "    for _ in range(num_of_words):\n",
    "        input_sequence = tokenizer.texts_to_sequences([seed_text])\n",
    "        input_sequence = pad_sequences(input_sequence, maxlen=mean) \n",
    "        predictions = model.predict(input_sequence)\n",
    "\n",
    "        predicted_word_index = predictions.argmax(axis=1)\n",
    "        predicted_word = tokenizer.index_word[predicted_word_index[0]]    \n",
    "        seed_text +=  ' ' + predicted_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word_LSTM(seed_text, num_of_words):\n",
    "    for _ in range(num_of_words):\n",
    "        input_sequence = tokenizer.texts_to_sequences([seed_text])\n",
    "        input_sequence = pad_sequences(input_sequence, maxlen=mean) \n",
    "        predictions = model_LSTM.predict(input_sequence)\n",
    "\n",
    "        predicted_word_index = predictions.argmax(axis=1)\n",
    "        predicted_word = tokenizer.index_word[predicted_word_index[0]]    \n",
    "        seed_text +=  ' ' + predicted_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = [\"السعودية\", \"النصر\", \"قال\", \"علي\", \"الهلال\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "samples = dict()\n",
    "\n",
    "for sen in seed_words:    \n",
    "    samples.update({sen: predict_next_word(sen, random.randint(1, 9))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>السعودية</td>\n",
       "      <td>السعودية مسوي مكان فاضي ايش يسوي السبت يعني هسه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>النصر</td>\n",
       "      <td>النصر ي آجمل صباحات العمر حبا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قال</td>\n",
       "      <td>قال ريال ل فائز ماذا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>علي</td>\n",
       "      <td>علي أبي طالب رضي الله عنه رسول الله</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الهلال</td>\n",
       "      <td>الهلال ينتصر لكنه بعيد جدا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start                                        predicted\n",
       "0  السعودية  السعودية مسوي مكان فاضي ايش يسوي السبت يعني هسه\n",
       "1     النصر                    النصر ي آجمل صباحات العمر حبا\n",
       "2       قال                             قال ريال ل فائز ماذا\n",
       "3       علي              علي أبي طالب رضي الله عنه رسول الله\n",
       "4    الهلال                       الهلال ينتصر لكنه بعيد جدا"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(samples.items(), columns=[\"start\", \"predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "samples = dict()\n",
    "\n",
    "for sen in seed_words:    \n",
    "    samples.update({sen: predict_next_word_LSTM(sen, random.randint(1, 9))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>السعودية</td>\n",
       "      <td>السعودية الله الله أكبر لاحول ولاقوة بالله</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>النصر</td>\n",
       "      <td>النصر الهلال ايفون xr مقدم أحد الشخصيات الشخصيات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قال</td>\n",
       "      <td>قال يا الله</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>علي</td>\n",
       "      <td>علي الله الله وملائكته يصلون النبي ﷺ ﷺ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الهلال</td>\n",
       "      <td>الهلال إذن بكل بساطة إنتظار هدايا الحكم</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start                                         predicted\n",
       "0  السعودية        السعودية الله الله أكبر لاحول ولاقوة بالله\n",
       "1     النصر  النصر الهلال ايفون xr مقدم أحد الشخصيات الشخصيات\n",
       "2       قال                                       قال يا الله\n",
       "3       علي            علي الله الله وملائكته يصلون النبي ﷺ ﷺ\n",
       "4    الهلال           الهلال إذن بكل بساطة إنتظار هدايا الحكم"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(samples.items(), columns=[\"start\", \"predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN :\n",
      "Time for training :  9.233 hours\n",
      "loss 6.536467552185059\n",
      "accuracy 0.4504719078540802\n",
      "##############################\n",
      "LSTM :\n",
      "Time for training : 3.5667 hours\n",
      "loss 6.827205657958984\n",
      "accuracy 0.3848962187767029\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN :\")\n",
    "print(\"Time for training :  9.233 hours\")\n",
    "print(\"loss\",loss)\n",
    "print(\"accuracy\",accuracy)\n",
    "print(\"#\"*30)\n",
    "print(\"LSTM :\")\n",
    "print(\"Time for training : 3.5667 hours\")\n",
    "print(\"loss\",loss_LSTM)\n",
    "print(\"accuracy\",accuracy_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RNN model is considered the best because it has the highest number of epochs, totaling 10 epochs. Conversely, the LSTM model is considered the worst as it has the lowest number of epochs, specifically 3 epochs.\n",
    "if we increase the number of epochs we will get better result in both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
